#########################################################
# Great Lakes Seq package for low-level processing of RNA-Seq data
# Oleg Moskvin; info@scienceforever.com 
# Sept 18, 2013 
#########################################################
# 
# This is the top-level executable script  
#
#########################################################
#
# Usage: Rscript GLSeq.top.R (no)update (no)dataprep (no)exprcalc (no)collect expID
#
#########################################################
#
args <- commandArgs(trailingOnly = TRUE)
#
# update attributes from DB? (otherwise, use values from GLSeg.R as is)
# values: "update", "noupdate" or the name of a particular file with run attributes (GLSeq.attr.XXX.R)
updateFromDb <- as.character(args[1])
#
# prepare data from fastq.gz files? (if not, the split and ready fastq files must be already in the dest.dir)
# values: "dataprep", "nodataprep"
dataPrepare <- as.character(args[2])
#
# compute expression? 
# values: "exprcalc", "noexprcalc" 
exprRun <- as.character(args[3])
# 
# collect results? 
# values: "collect", "nocollect" 
resCollect <- as.character(args[4])
#
# experiment ID
# unique experiment ID used as a key to retrieve atributes from the database for the data processing 
# Text addition to the output files (after library name)
# typically - unique ID of the experiment
# the ID of the run (text.add) generated by the script itself, will be this value concatenated with serial number (01...99) 
expID <- as.character(args[5])
#
# protocol ID
# unique protocol ID used as a key to retrieve atributes from the "protocol" table od the DB 
protID <- as.character(args[6])
#
# full path to the attribute file of this particular run 
# this replaces the original reading of the attribute file from the GLSeq folder (may cause conflicts if more than 1 user want to use GLSeq at the same time)
attrPath <- as.character(args[7])
#
source("GLSeq.Util.R")
#
###################
# Getting input values:
# defaults
###################
#
# Even with "update" selected, attributes are read from the local file first
# to prime the objects in the environment: 
# 'noupdate' leads to using attributes from GLSeq.attr.R 
# 'update' means updatimg from / writing back to a test MySQL database
# 'GLOWNG' results in overwriting attributes from GLSeq.attr.R with new values from GLOW-NG and writing results back to GLOW-NG via web services 
# 
source(attrPath)
#
#    REWRITE the following line when incorporating GLOW-NG communication! 
# 
if (updateFromDb != "update" & updateFromDb != "noupdate") source(updateFromDb)
#
# generating text.add from local attribute file:
if (updateFromDb == "noupdate") {
earlierResults <- dir(base.dir)
earlierResults <- earlierResults[grep(".rda", earlierResults)]
earlierResults <- earlierResults[grep(expID, earlierResults)]
runAttempt <- length(earlierResults) + 1
if (runAttempt < 100) runAttempt <- formatC(runAttempt, width=2, flag="0")
if (runAttempt >= 100) runAttempt <- formatC(runAttempt, width=3, flag="0") # will probably never happen
#
# the real text.add that will be used as a common ID for all the GLSeq scripts is generated right here:
text.add <- paste(expID, runAttempt, sep=".") }
#
# generating text.add for the case of a custom updateFromDb record (including GLOWNG)
# (will not happen anytime soon)
#
#@@@@@@@@@@@@@@@
# Getting input values
# defaults
# End 
#@@@@@@@@@@@@@@@
#
picardToolsPath <- trailDirCheck(picardToolsPath)
##############
# Getting input values:
# updating from database
# if needed
##############
# a record of the current run is always saved in the database,
# even if the update from DB is suppressed
if (updateFromDb == "update") {
require(RMySQL)
dbcon <- dbConnect(MySQL(), group="glseq")
#
# looking for previousely run results with this expID: 
earlierResults <- dbGetQuery(dbcon, paste("select * from glseqresults where expid = ", "'",expID,"'", sep=""))
runAttempt <- nrow(earlierResults) + 1
if (runAttempt < 100) runAttempt <- formatC(runAttempt, width=2, flag="0")
if (runAttempt >= 100) runAttempt <- formatC(runAttempt, width=3, flag="0") # will probably never happen
#
# the real text.add that will be used as a common ID for all the GLSeq scripts is generated right here:
text.add <- paste(expID, runAttempt, sep=".")
if (sum(text.add %in% as.character(earlierResults$textadd)) > 0) stop("a record with the current textadd ID - ",  text.add, " - already exists in the database") 
if (sum("submited" %in% as.character(earlierResults$status)) > 0) warning("a Submitted record for the current experiment ID already exist in the database! \n Please make sure you indeed want to run a parallel computation for this dataset \n ") 
if (sum("submited" %in% as.character(earlierResults$status)) > 99) stop("at least 99 Submitted records for the current experiment ID already exist in the database! \n Please cleanup the records and check for orphaned computational processes first \n ") 
#
# Destination directory for the processed files 
dest.dir <- paste(dest.dir.base, text.add, "/", sep="")
#
# reading attributes from JGI:
jgiData <- dbGetQuery(dbcon, paste("select * from glseqjgi where expid = ", "'",expID,"'", sep=""))
Sys.sleep(10)
# the following .JGI versions of the 4 protocol attributes are used 
# to check for consistency between requested entires in jgi and protocol tables: 
strain.JGI <- as.character(jgiData$strain)
paired.end.JGI <- as.character(jgiData$paired)
qScores.JGI <- as.character(jgiData$qscores)
libstrand.JGI <- as.character(jgiData$libstrand)
# checking is all the libraries associated with the requested runID in JGI table have the same entries 
# in the 4 fields: 
if (length(unique(strain.JGI)) > 1) stop("non-unique STRAIN entires for the requested library files in JGI table!") 
if (length(unique(paired.end.JGI)) > 1) stop("non-unique PAIRED.END entires for the requested library files in JGI table!") 
if (length(unique(qScores.JGI)) > 1) stop("non-unique QSCORES entires for the requested library files in JGI table!") 
if (length(unique(libstrand.JGI)) > 1) stop("non-unique LIBSTRAND entires for the requested library files in JGI table!") 
# keeping 1 value per attribute (in JGI table, those are vectors of attributes):
strain.JGI <- unique(strain.JGI)
paired.end.JGI <- unique(paired.end.JGI)
qScores.JGI <- unique(qScores.JGI)
libstrand.JGI <- unique(libstrand.JGI)
#
# reading protocol-related attributes: 
protocolData <- dbGetQuery(dbcon, paste("select * from glseqprotocol where protid = ", "'",protID,"'", sep=""))
Sys.sleep(10)
# attributes from JGI table: 
raw.dir <- as.character(jgiData$rawdir) # vector
libList <-  as.character(jgiData$libfile) # vector
medium <-  as.character(jgiData$lmedium) # vector
timepoint <-  as.character(jgiData$timepoint) # vector
repNum <-  as.character(jgiData$repnum) # vector
# (strain.JGI, paired.end.JGI, qScores.JGI and libstrand.JGI are already read) 
# 
# attributes from protocol table: 
dest.dir.base <- as.character(protocolData$destdirbase)
dest.dir.base <- trailDirCheck(dest.dir.base)
dest.dir <- paste(dest.dir.base, text.add, "/", sep="")
base.dir <- as.character(protocolData$basedir)
strain.prot <- as.character(protocolData$strain)
rGenome <- as.character(protocolData$rgenome)
paired.end.prot <- as.character(protocolData$paired)
qScores.prot <- as.character(protocolData$qscores) 
nCores <- as.numeric(protocolData$ncores)
nStreams <- as.numeric(protocolData$nstreams) 
compConf <- as.logical(as.character(protocolData$compconf))
rawGen <- as.logical(as.character(protocolData$rawgen))
qAlgor <- as.character(protocolData$qalgor)
genobam <- as.logical(as.character(protocolData$genobam)) 
libstrand.prot <- as.character(protocolData$libstrand)
strandBase <- as.character(protocolData$strandbase)
strandExtract <- as.logical(as.character(protocolData$strandextract))  
libNchar <- as.numeric(protocolData$libnchar) 
#
# checking for consistency of records for the 4 attributes in JGI and protocol tables: 
if (qScores.prot != qScores.JGI) stop("Quality scores format records are different in JGI and protocol tables! \n") 
if (paired.end.prot != paired.end.JGI) stop("Sequencing type records are different in JGI and protocol tables! \n") 
if (strain.prot != strain.JGI) stop("Strain name records are different in JGI and protocol tables! \n") 
if (libstrand.prot != libstrand.JGI) stop("Library strandness records are different in JGI and protocol tables! \n") 
#
#############################################################
# recoding JGI values for the 4 attributes into internal values of GLSeq (acceptable by RSEM etc): 
#############################################################
#
qScores <- NULL
paired.end <- NULL
strain <- NULL
libstrand <- NULL
# (preliminary wiping out the default values would help in case the subsequent rewriting doesn't happen 
# and we are silently left with irrelevant default values; we'll have helpful error + stopped computation)
if (qScores.prot %in% c("phred33", "Phred+33")) qScores <- "phred33" 
if (qScores.prot %in% c("phred64", "Phred+64")) qScores <- "phred64" 
if (paired.end.prot %in% c(TRUE, "blablabla")) paired.end <- TRUE # REPLACE WITH REAL JGI value
if (strain.prot %in% c("MT203pPET", "blablabla")) strain <- "MT203pPET" # REPLACE WITH REAL JGI value
if (libstrand.prot %in% c("R", "blablabla")) libstrand <- "R" # REPLACE WITH REAL JGI value
if (libstrand.prot %in% c("F", "blablabla")) libstrand <- "F" # REPLACE WITH REAL JGI value
#
##################
# recoding of attributes end
##################
} # if update from db
#
#@@@@@@@@@@
# Updating input values:
# End
#@@@@@@@@@@
#
# 
# base directory name with guaranteed trailing slash: 
base.dir <- trailDirCheck(base.dir)
#
# Destination directory for the processed files (if no connection to DB performed):
dest.dir <- paste(dest.dir.base, text.add, "/", sep="")
# destination directory name with guaranteed trailing slash: 
dest.dir <- trailDirCheck(dest.dir)
#
# raw directory name with guaranteed trailing slash: 
raw.dir <- trailDirCheck(raw.dir)
# readyData.dir checking
readyData.dir <- trailDirCheck(readyData.dir)
#
###
# the following directories are ALWAYS relative to the base directory!!!
#
# Destination directory for bam / wig files
destDirBam <- paste(dest.dir, text.add, ".viz/", sep="")
#
# Destination directory for count files + combined matrix
destDirCount <-  paste(dest.dir, text.add, ".counts/", sep="")
#
# Destination directory for log /stat files:
destDirLog <-  paste(dest.dir, text.add, ".stat/", sep="") 
#
#@@@@@@@@@@@@
# Directory name checkEnd
#@@@@@@@@@@@@
#
destDir.create <- paste("mkdir ", dest.dir, sep="")
destDirBam.create <- paste("mkdir ", destDirBam, sep="")
destDirCount.create <- paste("mkdir ", destDirCount, sep="")
destDirLog.create <- paste("mkdir ", destDirLog, sep="")
#
try(system(destDir.create))
try(system(destDirBam.create))
try(system(destDirCount.create))
try(system(destDirLog.create))
#
###############
# Log-tail command addition
###############
#
runLogFile1 <- paste(destDirLog, text.add, ".runLog1.txt", sep="")
runLogFile2 <- paste(destDirLog, text.add, ".runLog2.txt", sep="")
#
runErrFile1 <- paste(destDirLog, text.add, ".runErr1.txt", sep="")
runErrFile2 <- paste(destDirLog, text.add, ".runErr2.txt", sep="")
#
#
############################
# Preparing data file names (ready for expression computation)
############################
# 
# reusable function for assembly split fastq file names (see below)
fqfiles.table.pe.assemble <- function(fqfiles.base) {
fqfiles.table <- NULL
for (i in 1: length(fqfiles.base)) {
left.fq <- paste(fqfiles.base[i],".1.fq", sep="")
right.fq <- paste(fqfiles.base[i],".2.fq", sep="")
fqfiles.table <- rbind(fqfiles.table, c(left.fq, right.fq)) }
fqfiles.table }
#
###########
# A. If the library files are already decompressed and put into 
# the destination directory, i.e. when "nodataprep" is supplied as the second argument
###########
#
if(dataPrepare == "nodataprep") {
# copying the ready-to-process fastq files to the destination directory:
readyDataCopy <- paste("cp ", readyData.dir, "*.fq ", dest.dir, sep="")
system(readyDataCopy)
Sys.sleep(10)
if (paired.end) {
fqfiles <- dir(dest.dir) 
fqfiles <- fqfiles[grep(".fq", fqfiles)]
fqfiles.base <- substr(fqfiles, 1,nchar(fqfiles) - 5)
fqfiles.base <- unique(fqfiles.base)
# table of paires of FASTQ file names (1 pair per row):
# we assemble left and right file names explicitly here because 
# we don't want to rely on file sequence in the directory and get wrong results if there are occasional unpaired files etc. 
#
# assemble function for paired-end libraries:
fqfiles.table <- fqfiles.table.pe.assemble(fqfiles.base)
} # if paired-end
#
# for single-ended libraries: 
if (!(paired.end)) {
fqfiles <- dir(dest.dir) 
fqfiles <- fqfiles[grep(".fq", fqfiles)]
fqfiles.table <- cbind(NULL, fqfiles) }
} # if nodataprep
#
####### 
# B. If the data needs to be processed all the way
# from the compressed archives in the raw directory
#######
#
if(dataPrepare == "dataprep") {
if (paired.end) {
# here we have 2 possibilities:
# a) the list of rawfiles is supplied explicitly
# (in the case of "update" as the first argument) or
# b) only the raw directory is known (if "noupdate") 
if(updateFromDb == "update") {
if (is.null(libList)) stop("Apparently, no raw file names were retrieved from the database - nothing to work with \n")
fqfiles.base <- substr(libList, 1, nchar(libList)-3)
fqfiles.table <- fqfiles.table.pe.assemble(fqfiles.base)
} # if update
#
# no update from DB / no explicit list of raw files route: 
if(updateFromDb == "noupdate") {
gzfiles <- dir(raw.dir) 
gzfiles <- gzfiles[grep(".gz", gzfiles)]
fqfiles.base <- substr(gzfiles, 1,nchar(gzfiles) - 3)
fqfiles.table <- fqfiles.table.pe.assemble(fqfiles.base)
} # if noupdate
} # if paired-end
# single-end libraries without update from DB:
if (!(paired.end))  {
gzfiles <- dir(raw.dir) 
gzfiles <- gzfiles[grep(".gz", gzfiles)] # just in case raw.dir has somethig else besides .gz files
fqfiles <- substr(gzfiles, 1, nchar(gzfiles)-3)
fqfiles.table <- cbind(NULL, fqfiles) }
} # if dataprep
#@@@@@@@@@@@@@@@@@@@@@
# Preparing data file names End
#@@@@@@@@@@@@@@@@@@@@@
#
# 
############################
# Ranges of data to run as separate processes
############################
#
# range1 <- 1:floor(nrow(fqfiles.table) /2)
# range2 <- (floor(nrow(fqfiles.table) /2)+1):nrow(fqfiles.table)
# if (nrow(fqfiles.table) ==1) {
# range1 <- 1
# range2 <- NULL }
#
chunk <- function(x, n) split(x, sort(rank(x) %% n)) # commonly known solution
# if (nStreams > nrow(fqfiles.table)) stop('Please set the number of computation streams not exceeding the number rof libraries to process \n')
if (nStreams > nrow(fqfiles.table)) nStreams <- nrow(fqfiles.table) # quiet and nice solution but there will de descrepancy between nStreams in the attribute file and the actual nStreams (recorded in the .rda file - good news)
rangelist <- chunk(1:nrow(fqfiles.table), nStreams)
# ranges are in rangelist[1:nSreams]
for (ii in 1:nStreams) assign(paste("range",ii,sep=""),rangelist[[ii]])
#
#@@@@@@@@@@@@@@@@@@@@@
# Ranges of data End
#@@@@@@@@@@@@@@@@@@@@@
#
#
############################
# Expression quantification: 
############################
# 
if (qAlgor == "RSEM") source("GLSeq.RSEM.R")
if (qAlgor == "bwaHTSeq") source("GLSeq.bwaHTSeq.R") 
# 
###############
# saving the variables for this run
###############
setwd(base.dir)
currentRun.dataFile <- paste("GLSeq.vars.", text.add, ".rda", sep="")
if (currentRun.dataFile %in% dir(base.dir)) {
cat(timestamp(), " Attribute file for this run ID - ", " \n", currentRun.dataFile, " - is already saved; keeping the original file ", "\n")
currentRun.dataFile.base <- substr(currentRun.dataFile, 1, nchar(currentRun.dataFile) -4)
add.num <- 1 }
# saving a version of the attribute file with numeric addon:nStreams
while(currentRun.dataFile %in% dir(base.dir)) {
currentRun.dataFile <- paste(currentRun.dataFile.base, add.num, "rda", sep=".")
add.num <- add.num+1 }
if (!(currentRun.dataFile %in% dir(base.dir))) save.image(file=currentRun.dataFile)
#
# saving the record of the new run in the results table of the database:
if (updateFromDb == "update") {
glseqresults <- as.data.frame(cbind(expid=expID, protid=protID, rundate=runDate, runend=NULL, textadd=text.add, destdir=dest.dir, destdirbam=destDirBam, destdircount=destDirCount, destdirlog=destDirLog, status="Submitted")) 
dbWriteTable(dbcon, "glseqresults", glseqresults, row.names = FALSE, append=TRUE)
Sys.sleep(10)
dbDisconnect(dbcon) }
#
###############
#
# Start data preparation: 
if (dataPrepare  == "dataprep") {
Sys.sleep(10) 
dataPrepLog <- paste(destDirLog, text.add, ".DataPrepLog.txt", sep="")
dataPrepErr <- paste(destDirLog, text.add, ".DataPrepErr.txt", sep="")
dataPrep <- paste("Rscript GLSeq.dataprep.R ", text.add, " 1>> ", dataPrepLog, " 2>> ", dataPrepErr, " &", sep="") 
system(dataPrep) }
#
# Watch for readiness of the data files before starting the expression calculations: 
setwd(dest.dir)
DataIsWaiting <- FALSE 
if (dataPrepare  == "nodataprep") DataIsWaiting <- TRUE
dataReady.ind <- paste(text.add, ".DataReady", sep="") 
# 
while(!(DataIsWaiting)) {
Sys.sleep(21) 
DataIsWaiting <- dataReady.ind %in% dir(dest.dir) }
#
# Start the expression calculations:
# 
if (DataIsWaiting) {
Sys.sleep(10) 
#
##################################
###  HOT!!!!!!!!!!!!! running the computation: ####
##################################
system(comm.stack.pool) }
# 
#@@@@@@@@@@@@@@@@@@
# Expression quantification end 
#@@@@@@@@@@@@@@@@@@


















